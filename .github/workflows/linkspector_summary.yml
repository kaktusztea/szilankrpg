name: Linkspector summary

on:
  workflow_run:
    workflows:
      - "Linkspector wiki"
      - "Linkspector code"
    types: [completed]

permissions:
  checks: write        # allow creating check runs
  actions: read
  contents: read

jobs:
  summarize-broken-links:
    runs-on: ubuntu-latest
    env:
      SUMMARY_URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
    steps:
      - name: Download workflow run logs
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          WORKFLOW_RUN_ID: ${{ github.event.workflow_run.id }}
        run: |
          set -euo pipefail
          echo "Downloading logs for workflow run id: $WORKFLOW_RUN_ID"
          curl -fsSL -H "Authorization: token $GITHUB_TOKEN" \
            "https://api.github.com/repos/${{ github.repository }}/actions/runs/${WORKFLOW_RUN_ID}/logs" -o logs.zip
          unzip -q logs.zip -d logs
          # concatenate all job log files into one file (ignore errors)
          find logs -type f -name "*.txt" -print0 | xargs -0 cat > all_logs.txt || true
          wc -c all_logs.txt || true

      - name: Parse broken links and prepare payload
        env:
          GITHUB_EVENT_PATH: ${{ github.event_path }}
          WORKFLOW_NAME: ${{ github.event.workflow_run.name }}
        run: |
          python3 - <<'PY'
          import json, os, re, sys

          # read logs
          try:
              s = open('all_logs.txt', 'r', encoding='utf-8', errors='ignore').read()
          except FileNotFoundError:
              s = ''

          # two-pass extraction to match common Linkspector output patterns
          records = []
          pat1 = re.compile(r'message:\"Cannot reach\s+([^\"]+)\"\s+location:\{path:\"([^\"]+)\"\s+range:\{start:\{line:(\d+)', re.MULTILINE)
          for m in pat1.finditer(s):
              raw_url = m.group(1).strip()
              url = re.split(r'\s+Status:|\s+Cannot find:|\s+Cannot find section:', raw_url)[0].strip()
              path = m.group(2)
              line = m.group(3)
              records.append(f"{path}:{line} => {url}")

          pat2 = re.compile(r'message:\"Cannot reach\s+([^\"]+)\"[^\\n]*location:\{path:\"([^\"]+)\"', re.MULTILINE)
          for m in pat2.finditer(s):
              raw_url = m.group(1).strip()
              url = re.split(r'\s+Status:|\s+Cannot find:|\s+Cannot find section:', raw_url)[0].strip()
              path = m.group(2)
              # try to find nearby line number
              start = max(0, m.start()-200)
              end = min(len(s), m.end()+200)
              snippet = s[start:end]
              ln = re.search(r'line:(\d+)', snippet)
              line = ln.group(1) if ln else '(no line)'
              records.append(f"{path}:{line} => {url}")

          # deduplicate while preserving order
          seen = set(); uniq = []
          for r in records:
              if r not in seen:
                  seen.add(r); uniq.append(r)

          summary_lines = uniq if uniq else ["No broken links found."]
          # limit summary length (GitHub check output has limits)
          summary_text = "\n".join(summary_lines)
          if len(summary_text) > 60000:
              summary_text = summary_text[:60000] + "\n...truncated..."

          # event head SHA
          head_sha = ''
          try:
              ev = json.load(open(os.environ.get('GITHUB_EVENT_PATH')))
              head_sha = ev.get('workflow_run', {}).get('head_sha', '')
          except Exception:
              head_sha = ''

          payload = {
              "name": "Linkspector summary",
              "head_sha": head_sha,
              "status": "completed",
              # set conclusion: success when no broken links, neutral otherwise
              "conclusion": "success" if not uniq else "neutral",
              "details_url": os.environ.get('SUMMARY_URL',''),
              "output": {
                  "title": f"Linkspector summary for {os.environ.get('WORKFLOW_NAME','')}",
                  "summary": summary_text
              }
          }
          open('payload.json','w').write(json.dumps(payload))
          print('Prepared payload.json; head_sha=', head_sha)
          PY

      - name: Create Linkspector summary check run
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
        run: |
          set -euo pipefail
          if [ ! -f payload.json ]; then
            echo "payload.json not found; exiting" >&2
            exit 1
          fi
          cat payload.json
          # POST check run
          resp=$(curl -s -H "Authorization: token $GITHUB_TOKEN" -H "Accept: application/vnd.github+json" \
            -X POST "https://api.github.com/repos/$REPO/check-runs" \
            -d @payload.json)
          echo "$resp" | jq -r '.html_url // .url' || echo "$resp"
